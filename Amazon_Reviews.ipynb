{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanmcm/Sentiment-Analysis-Amazon-Musical-Instruments-Reviews/blob/main/Amazon_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pickle5\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnsaJPpR1Zwk",
        "outputId": "50084062-6a42-44e0-a810-5e641498c544"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from torchtext.legacy import data\n",
        "import pickle5 as pickle\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import params\n",
        "import net\n",
        "import numpy as np\n",
        "from dataset import AmazonDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "import dataset\n",
        "import net\n",
        "import params\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n"
      ],
      "metadata": {
        "id": "MLddvTBA4uPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756aaff2-91a7-4a55-b0ec-e12f7e57393a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "yLQaaBWxfTap"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_dataset(d, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(d.data.index), test_size=val_split)\n",
        "    return Subset(d, train_idx), Subset(d, val_idx)"
      ],
      "metadata": {
        "id": "Dz--B9wPoCUL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = AmazonDataset()\n",
        "dataset.load_dataset()\n",
        "dataset.my_filter()\n",
        "train_dataset, test_dataset = train_val_dataset(dataset)"
      ],
      "metadata": {
        "id": "oTr2Q-hTPbAp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe66bTvcrEsB",
        "outputId": "70c00b67-bad0-496b-b79e-98210fab646b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H28Hsmiktkmn",
        "outputId": "2671695f-20e1-4cc6-b825-58e9bb8fd0d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0124, -0.6572],\n",
              "        [ 0.5605, -0.5754],\n",
              "        [ 0.8085, -0.2907]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(4,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx5k3y2jtncy",
        "outputId": "8a0dfc5b-a650-4e6c-f5d8-7aba1abcd187"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4053,  0.9873],\n",
              "        [-0.0549,  0.1335],\n",
              "        [ 0.6608, -1.5051],\n",
              "        [-0.8374, -0.0481]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(5,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gTyhcw8vDmU",
        "outputId": "e067194c-eefb-43f8-f3e3-fcec46baacf4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3954,  0.3709],\n",
              "        [ 0.3078, -0.6092],\n",
              "        [ 0.6654, -1.0872],\n",
              "        [ 1.8260, -1.3132],\n",
              "        [ 1.3139,  0.4920]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = train_dataset\n"
      ],
      "metadata": {
        "id": "7w4Mx8dm3qpm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [torch.randn(3,2), torch.randn(4,2), torch.randn(5,2)] \n",
        "# nel nostro caso l = [recensione1, recensione2, ...],\n",
        "# quindi nel caso esempio la lunghezza di ogni parola nella recensione è 2, nel nostro in questo case specifico è come se ogni lunghe\n",
        "print(l)\n",
        "print(\"----\")\n",
        "out = torch.nn.utils.rnn.pad_sequence(l, batch_first=True)\n",
        "print(out)\n",
        "print(\"----\")\n",
        "l_final = torch.split(out, [1,1,1])\n",
        "print(l_final)\n",
        "print(\"----\")\n",
        "'''\n",
        "# out will now be a tensor with shape (3, 5, 2)\n",
        "# You can transpose it back to (3, 2, 5) with\n",
        "out = out.transpose(1, 2)\n",
        "print(out)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "eSxRiQTornut",
        "outputId": "f942ea0b-1949-4f2e-964e-98e032f7dbdb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 1.3914, -0.5865],\n",
            "        [-1.2992, -1.0501],\n",
            "        [-0.7417, -1.2190]]), tensor([[-0.2214,  1.5253],\n",
            "        [-0.4063, -0.4586],\n",
            "        [ 0.5411,  0.3608],\n",
            "        [-0.1357, -0.1388]]), tensor([[-1.0698,  0.2527],\n",
            "        [-1.0860, -0.2793],\n",
            "        [-0.3274, -1.2031],\n",
            "        [ 0.5366,  0.0464],\n",
            "        [-0.2293,  0.6556]])]\n",
            "----\n",
            "tensor([[[ 1.3914, -0.5865],\n",
            "         [-1.2992, -1.0501],\n",
            "         [-0.7417, -1.2190],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.2214,  1.5253],\n",
            "         [-0.4063, -0.4586],\n",
            "         [ 0.5411,  0.3608],\n",
            "         [-0.1357, -0.1388],\n",
            "         [ 0.0000,  0.0000]],\n",
            "\n",
            "        [[-1.0698,  0.2527],\n",
            "         [-1.0860, -0.2793],\n",
            "         [-0.3274, -1.2031],\n",
            "         [ 0.5366,  0.0464],\n",
            "         [-0.2293,  0.6556]]])\n",
            "----\n",
            "(tensor([[[ 1.3914, -0.5865],\n",
            "         [-1.2992, -1.0501],\n",
            "         [-0.7417, -1.2190],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000]]]), tensor([[[-0.2214,  1.5253],\n",
            "         [-0.4063, -0.4586],\n",
            "         [ 0.5411,  0.3608],\n",
            "         [-0.1357, -0.1388],\n",
            "         [ 0.0000,  0.0000]]]), tensor([[[-1.0698,  0.2527],\n",
            "         [-1.0860, -0.2793],\n",
            "         [-0.3274, -1.2031],\n",
            "         [ 0.5366,  0.0464],\n",
            "         [-0.2293,  0.6556]]]))\n",
            "----\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# out will now be a tensor with shape (3, 5, 2)\\n# You can transpose it back to (3, 2, 5) with\\nout = out.transpose(1, 2)\\nprint(out)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "dataset.maximum_embedding_len = 500\n",
        "\n",
        "# Define parameters\n",
        "batch_size = params.BATCH_SIZE\n",
        "hidden_dim = 128\n",
        "embedding_size = len(dataset.__getitem__(0)[0])  # lunghezza embedding (selezionato uno a caso perchè tanto tutti hanno la stessa dimensione)\n",
        "dropout_rate = params.DROPOUT_RATE\n",
        "lr = params.LR\n",
        "epochs = params.NUM_EPOCHS\n",
        "best_loss = float('inf')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)  # , collate_fn=None, pin_memory=False)\n",
        "# Build the model\n",
        "lstm_model = net.SentimentAnalysis(batch_size,\n",
        "                                   hidden_dim,\n",
        "                                   embedding_size,\n",
        "                                   dropout_rate)  # modificato LSTM con SentimentAnalysis (nome rete)\n",
        "\n",
        "# optimization algorithm\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)\n",
        "\n",
        "to_train = True\n",
        "\n",
        "ce = nn.CrossEntropyLoss()\n",
        "mse = nn.MSELoss()\n",
        "# train and validate\n",
        "if to_train:\n",
        "    for epoch in range(epochs):\n",
        "        # training\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for idxs, (batch, labels) in enumerate(train_loader):\n",
        "            #print(batch)\n",
        "            batch = torch.stack(batch) #torch.from_numpy(batch)\n",
        "            if idxs == 0:\n",
        "              print(batch)\n",
        "            #padded_data = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "            optimizer.zero_grad()\n",
        "            predictions = lstm_model(batch)  # (text, text_lengths) # batch_size, hidden_dim, vocab_size, window, dropout_rate\n",
        "            loss = 0.5 * ce(predictions, labels) + 0.5 * mse(predictions, labels)\n",
        "            #winners = predictions.argmax(dim=1)\n",
        "            #corrects = np.where(winners == batch.labels)\n",
        "            #accuracy = corrects.sum().float() / float(batch.labels.size(0))\n",
        "\n",
        "            accuracy = accuracy_score(predicitons, labels)\n",
        "            # perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += accuracy.item()\n",
        "\n",
        "        train_loss, train_acc = epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n",
        "\n",
        "        # save best model\n",
        "        if train_loss < best_loss:\n",
        "            best_valid_loss = train_loss\n",
        "            torch.save(lstm_model.state_dict(), 'saved_weights_BiLSTM.pt')\n",
        "\n",
        "        print(f'\\tEpoch; {epoch} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "\n",
        "# load weights and make predictions\n",
        "lstm_model.load_state_dict(torch.load(\"saved_weights_BiLSTM.pt\"))\n",
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "\n",
        "lstm_model.eval()\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)  # , collate_fn=None, pin_memory=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, batch in test_loader:\n",
        "        text, text_lengths = batch.text\n",
        "\n",
        "        predictions = lstm_model(batch).squeeze(1)\n",
        "\n",
        "        loss = 0.5 * ce(predictions, batch.labels) + 0.5 * mse(predictions, batch.labels)\n",
        "\n",
        "        winners = predictions.argmax(dim=1)\n",
        "        corrects = (winners == batch.labels)\n",
        "        accuracy = corrects.sum().float() / float(batch.labels.size(0))\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += accuracy.item()\n",
        "\n",
        "test_loss, test_acc = epoch_loss / len(test_iterator), epoch_acc / len(test_iterator)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73Bw24UOaIvY",
        "outputId": "27ff315a-a208-4f95-d1a9-869e09a7e6d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
            "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
            "         [-0.0462,  0.0173,  0.0558,  ..., -0.0424,  0.0095,  0.0594],\n",
            "         ...,\n",
            "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
            "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
            "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
            "\n",
            "        [[-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
            "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
            "         ...,\n",
            "         [ 0.0957, -0.2721,  1.3933,  ..., -0.6428, -0.1246, -0.6490],\n",
            "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
            "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
            "\n",
            "        [[ 0.0091, -0.0929,  0.1970,  ..., -0.1409,  0.7560, -0.6236],\n",
            "         [ 0.0171, -0.0574,  0.0526,  ..., -0.0564,  0.0306, -0.0275],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
            "         ...,\n",
            "         [ 0.2845,  0.3164,  1.0093,  ..., -0.6501, -0.3373, -0.2318],\n",
            "         [-0.0746,  0.0482,  0.1092,  ...,  0.0192,  0.0403,  0.0938],\n",
            "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-74f851d4ad89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#padded_data = pad_sequence(batch, batch_first=True, padding_value=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (text, text_lengths) # batch_size, hidden_dim, vocab_size, window, dropout_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#winners = predictions.argmax(dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         \u001b[0mhs_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhs_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                         \u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lstm_cell.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, state)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtmp3\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x3072 and 500x512)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problemi:\n",
        "1. Stiamo passando alla rete le frasi di testo (dataset.data) non tensori. In che formato vanno passati al modello? getitem restituisce una lista di elementi, dove ogni elemento è un tensore (ogni tensore corrisponde ad una parola della recenzione e ha lunghezza 3072) e la lunghezza della recensione è variabile\n",
        "2. Attention weight va ancora chiamato\n",
        "3. In dataset.embedded_wordataset_dict ci sono parole (keys) con \"##\" davanti, credo non ci debbano essere? (vedi cella sotto)"
      ],
      "metadata": {
        "id": "tXJIPOiDJV1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_data = dataset.format_data()"
      ],
      "metadata": {
        "id": "rzPwmjQTHGdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [lambda x : len(x) for x in dataset.data.split(\"\")]\n",
        "print(lengths)"
      ],
      "metadata": {
        "id": "P61Qg0Le_Eqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset.embedded_data, dataset.labels, train_size=0.7, random_state=0, shuffle = False)\n",
        "\n",
        "\n",
        "training_set = DatasetMapper(x_train, y_train)\n",
        "test_set = DatasetMapper(x_test, y_test)\n",
        "\n",
        "batch_size = params.BATCH_SIZE\n",
        "\n",
        "loader_training = DataLoader(training_set, batch_size=batch_size)\n",
        "loader_test = DataLoader(test_set)"
      ],
      "metadata": {
        "id": "w66eIo9O7tgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.labels, train_size=0.7, random_state=0, shuffle = True)\n",
        "\n",
        "train_data = { 'features': x_train, 'labels': y_train}\n",
        "test_data = {'features': x_test, 'labels': y_test}\n",
        "\n",
        "train_data = pd.DataFrame(train_data)\n",
        "test_data = pd.DataFrame(test_data)\n",
        "'''"
      ],
      "metadata": {
        "id": "pZoAXraSUWan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "batch_size = params.BATCH_SIZE\n",
        "hidden_dim = 128\n",
        "embedding_size = len(dataset.__getitem__(0)[0]) #lunghezza embedding (selezionato uno a caso perchè tanto tutti hanno la stessa dimensione)\n",
        "dropout_rate = params.DROPOUT_RATE\n",
        "lr = params.LR\n",
        "epochs = params.NUM_EPOCHS\n",
        "best_loss = float('inf')\n",
        "\n",
        "# BucketIterator : Defines an iterator that batches examples of similar lengths together to minimize the amount of padding needed.\n",
        "# x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, train_size=0.8, random_state=0)\n",
        "'''\n",
        "train_iterator, test_iterator = data.BucketIterator.splits((train_data, test_data),\n",
        "    batch_size = batch_size,\n",
        "    sort_key = lambda x: len(x.text), # Sort the batches by text length size\n",
        "    sort_within_batch = True,\n",
        "    device = device)\n",
        "\n",
        "train_iterator = DataLoader(train_data, batch_size=batch_size)\n",
        "test_iterator = DataLoader(test_data, batch_size = batch_size)\n",
        "'''\n",
        "# Build the model\n",
        "lstm_model = net.SentimentAnalysis(batch_size,\n",
        "                                   hidden_dim,\n",
        "                                   embedding_size,\n",
        "                                   dropout_rate) #modificato LSTM con SentimentAnalysis (nome rete)\n",
        "\n",
        "# optimization algorithm\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "bRyMu10RVfrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_training.dataset[9]"
      ],
      "metadata": {
        "id": "BCW2fE209oRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_train = True\n",
        "\n",
        "# train and validate\n",
        "if (to_train):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # training \n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for batch in loader_training:\n",
        "            optimizer.zero_grad()\n",
        "            # retrieve text and no. of wordataset\n",
        "            #text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = lstm_model(batch)    #(text, text_lengths) # batch_size, hidden_dim, vocab_size, window, dropout_rate\n",
        "            loss = 0.5*nn.CrossEntropyLoss(predictions, batch.labels.squeeze())+ 0.5*nn.MSELoss(predictions, batch.labels.squeeze())\n",
        "            '''\n",
        "            winners = predictions.argmax(dim=1)\n",
        "            corrects = (winners == batch.labels)\n",
        "            accuracy = corrects.sum().float() / float(batch.labels.size(0))\n",
        "            '''\n",
        "            accuracy=accuracy_score(kept_labels, predictions)\n",
        "\n",
        "            # perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += accuracy.item()\n",
        "            \n",
        "        train_loss, train_acc = epoch_loss / len(train_iterator), epoch_acc / len(train_iterator)\n",
        "\n",
        "        # save best model\n",
        "        if train_loss < best_loss:\n",
        "            best_valid_loss = train_loss\n",
        "            torch.save(lstm_model.state_dict(), 'saved_weights_BiLSTM.pt')\n",
        "\n",
        "        print(f'\\tEpoch; {epoch} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')  "
      ],
      "metadata": {
        "id": "piGVJCc1r3t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights and make predictions\n",
        "lstm_model.load_state_dict(torch.load(\"saved_weights_BiLSTM.pt\"))\n",
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "\n",
        "lstm_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "        text, text_lengths = batch.text\n",
        "\n",
        "        predictions = lstm_model(batch).squeeze(1)\n",
        "\n",
        "        loss = 0.5*nn.CrossEntropyLoss(predictions, batch.labels)+ 0.5*nn.MSELoss(predictions, batch.labels)\n",
        "\n",
        "        winners = predictions.argmax(dim=1)\n",
        "        corrects = (winners == batch.labels)\n",
        "        accuracy = corrects.sum().float() / float(batch.labels.size(0))\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += accuracy.item()\n",
        "\n",
        "test_loss, test_acc =  epoch_loss / len(test_iterator), epoch_acc / len(test_iterator)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "fHlRh2BGW1sq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}